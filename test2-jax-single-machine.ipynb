{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jax-dataloader -q","metadata":{"execution":{"iopub.status.busy":"2024-06-03T06:58:05.345491Z","iopub.execute_input":"2024-06-03T06:58:05.346431Z","iopub.status.idle":"2024-06-03T06:58:24.727075Z","shell.execute_reply.started":"2024-06-03T06:58:05.346390Z","shell.execute_reply":"2024-06-03T06:58:24.725693Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U \"jax[cuda12]\" -q","metadata":{"execution":{"iopub.status.busy":"2024-06-03T06:58:24.728837Z","iopub.execute_input":"2024-06-03T06:58:24.729150Z","iopub.status.idle":"2024-06-03T06:59:57.089975Z","shell.execute_reply.started":"2024-06-03T06:58:24.729122Z","shell.execute_reply":"2024-06-03T06:59:57.088742Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nfrom jax import jit\nimport optax\nfrom transformers import MarianTokenizer, MarianMTModel, FlaxMarianMTModel\nfrom datasets import load_dataset, load_metric, DatasetDict\nfrom flax.training import train_state\nimport flax\nfrom jax import random\nfrom functools import partial\nimport time\nfrom typing import Callable\nimport jax_dataloader as jdl\nfrom tqdm import tqdm\nfrom time import time\nimport numpy as np\nfrom flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T06:59:57.091625Z","iopub.execute_input":"2024-06-03T06:59:57.092043Z","iopub.status.idle":"2024-06-03T07:00:17.679346Z","shell.execute_reply.started":"2024-06-03T06:59:57.092005Z","shell.execute_reply":"2024-06-03T07:00:17.678462Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-03 07:00:07.795434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-03 07:00:07.795597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-03 07:00:07.915651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"print('JAX is running on', jax.lib.xla_bridge.get_backend().platform)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:17.681984Z","iopub.execute_input":"2024-06-03T07:00:17.683114Z","iopub.status.idle":"2024-06-03T07:00:17.870977Z","shell.execute_reply.started":"2024-06-03T07:00:17.683069Z","shell.execute_reply":"2024-06-03T07:00:17.870032Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"JAX is running on gpu\n","output_type":"stream"}]},{"cell_type":"code","source":"jax.local_devices()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:17.872043Z","iopub.execute_input":"2024-06-03T07:00:17.872301Z","iopub.status.idle":"2024-06-03T07:00:17.879371Z","shell.execute_reply.started":"2024-06-03T07:00:17.872278Z","shell.execute_reply":"2024-06-03T07:00:17.878432Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[cuda(id=0)]"},"metadata":{}}]},{"cell_type":"code","source":"def get_config():\n    config = {\n        'model_name': 'Helsinki-NLP/opus-mt-en-hu', # 't5-small', \n        'max_length': 64,\n        'batch_size': 64,\n        'lr': 10 ** -5,\n        'epochs': 10,\n        'seed': 42,\n        'metric_name': 'sacrebleu',\n        'save_model': '/kaggle/working/model.pth',\n        'per_device_batch_size': 64\n        \n    }\n    return config","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:17.880877Z","iopub.execute_input":"2024-06-03T07:00:17.881368Z","iopub.status.idle":"2024-06-03T07:00:17.888589Z","shell.execute_reply.started":"2024-06-03T07:00:17.881332Z","shell.execute_reply":"2024-06-03T07:00:17.887641Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"config = get_config()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:17.889756Z","iopub.execute_input":"2024-06-03T07:00:17.890365Z","iopub.status.idle":"2024-06-03T07:00:17.898637Z","shell.execute_reply.started":"2024-06-03T07:00:17.890332Z","shell.execute_reply":"2024-06-03T07:00:17.897657Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load dataset and metric\ndataset = load_dataset('Helsinki-NLP/opus_books', 'en-hu')\nval_test_set = dataset['train'].train_test_split(test_size=0.2, seed=42)\ntest_set = val_test_set['test'].train_test_split(test_size=0.5, seed=42)\n\ndataset = DatasetDict({\n    'train': val_test_set['train'],\n    'val': test_set['test'],\n    'test': test_set['train']\n})","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:17.899723Z","iopub.execute_input":"2024-06-03T07:00:17.900299Z","iopub.status.idle":"2024-06-03T07:00:21.262157Z","shell.execute_reply.started":"2024-06-03T07:00:17.900273Z","shell.execute_reply":"2024-06-03T07:00:21.261351Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/28.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d297d69a061d4ea0a2638450e366d8c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/23.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fa48d8f25f4cb1a7951b95e00fd392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/137151 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef96b8e5f3ae47228fc86e53d16512b3"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = MarianTokenizer.from_pretrained(config['model_name'])\n# Load the model\nmodel = FlaxMarianMTModel.from_pretrained(config['model_name'], from_pt=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:21.263439Z","iopub.execute_input":"2024-06-03T07:00:21.264055Z","iopub.status.idle":"2024-06-03T07:00:33.353927Z","shell.execute_reply.started":"2024-06-03T07:00:21.264007Z","shell.execute_reply":"2024-06-03T07:00:33.353041Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a164a6d6744b50af784120ced89ead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c278575e759249ab8cb4736e74f3dbb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/850k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d82c477ad849af966191ed7905e57f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.57M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1405bc9812454b8e891fef3464df1b17"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04be0dad2d0e4f1d997ce90366640219"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b07b52de14149a4b76c761a27f7093a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of the model checkpoint at Helsinki-NLP/opus-mt-en-hu were not used when initializing FlaxMarianMTModel: {('model', 'encoder', 'embed_positions', 'kernel'), ('model', 'decoder', 'embed_tokens', 'kernel'), ('model', 'encoder', 'embed_tokens', 'kernel'), ('model', 'decoder', 'embed_positions', 'kernel')}\n- This IS expected if you are initializing FlaxMarianMTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing FlaxMarianMTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad40854cf3546179853b849d51c8350"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_fn(dataset: DatasetDict):\n    inputs = [ex['en'] for ex in dataset['translation']]\n    targets = [ex['hu'] for ex in dataset['translation']]\n    model_inputs = tokenizer(inputs, max_length=config['max_length'], truncation=True, padding='longest')\n\n    # tokenizer targets \n    #with tokenizer.as_target_tokenizer():\n    labels =  tokenizer(targets, max_length=config['max_length'], truncation=True, padding='longest')\n        \n    model_inputs['labels'] = labels.input_ids\n\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:33.358438Z","iopub.execute_input":"2024-06-03T07:00:33.358747Z","iopub.status.idle":"2024-06-03T07:00:33.365279Z","shell.execute_reply.started":"2024-06-03T07:00:33.358721Z","shell.execute_reply":"2024-06-03T07:00:33.364419Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess_fn, batched=True, remove_columns=dataset[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:00:33.366617Z","iopub.execute_input":"2024-06-03T07:00:33.366930Z","iopub.status.idle":"2024-06-03T07:01:42.917693Z","shell.execute_reply.started":"2024-06-03T07:00:33.366905Z","shell.execute_reply":"2024-06-03T07:01:42.916719Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/109720 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da161e581cb4e01b258c3a45d110d4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d83ea4ba02bf4dee9530980a637a57db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13715 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeef1e9cc6054bf681159d9616a7bad3"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:42.921089Z","iopub.execute_input":"2024-06-03T07:01:42.921460Z","iopub.status.idle":"2024-06-03T07:01:42.930354Z","shell.execute_reply.started":"2024-06-03T07:01:42.921423Z","shell.execute_reply":"2024-06-03T07:01:42.929394Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 109720\n    })\n    val: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 13716\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 13715\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataloader","metadata":{}},{"cell_type":"code","source":"train_loader = jdl.DataLoader(tokenized_datasets['train'], 'jax', batch_size=config['batch_size'], shuffle=True, )\nval_loader = jdl.DataLoader(tokenized_datasets['val'], 'jax', batch_size=config['batch_size'], shuffle=False)\ntest_loader = jdl.DataLoader(tokenized_datasets['test'], 'jax', batch_size=config['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:42.931829Z","iopub.execute_input":"2024-06-03T07:01:42.932256Z","iopub.status.idle":"2024-06-03T07:01:42.967534Z","shell.execute_reply.started":"2024-06-03T07:01:42.932231Z","shell.execute_reply":"2024-06-03T07:01:42.966552Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i in train_loader:\n    print(type(i['input_ids'][0]))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:42.969678Z","iopub.execute_input":"2024-06-03T07:01:42.970066Z","iopub.status.idle":"2024-06-03T07:01:45.621870Z","shell.execute_reply.started":"2024-06-03T07:01:42.970039Z","shell.execute_reply":"2024-06-03T07:01:45.620895Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tokenizer and model","metadata":{}},{"cell_type":"code","source":"total_batch_size = config['per_device_batch_size'] * jax.local_device_count()\nprint(\"The overall batch size (both for training and eval) is\", total_batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:45.623384Z","iopub.execute_input":"2024-06-03T07:01:45.624031Z","iopub.status.idle":"2024-06-03T07:01:45.629205Z","shell.execute_reply.started":"2024-06-03T07:01:45.623996Z","shell.execute_reply":"2024-06-03T07:01:45.628173Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"The overall batch size (both for training and eval) is 64\n","output_type":"stream"}]},{"cell_type":"code","source":"num_train_steps = len(dataset['train']) // total_batch_size * config['epochs']\n\nlearning_rate_function = optax.linear_schedule(init_value=config['lr'], end_value=0, transition_steps=num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:45.630415Z","iopub.execute_input":"2024-06-03T07:01:45.630752Z","iopub.status.idle":"2024-06-03T07:01:45.640485Z","shell.execute_reply.started":"2024-06-03T07:01:45.630717Z","shell.execute_reply":"2024-06-03T07:01:45.639638Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    loss_function: Callable = flax.struct.field(pytree_node=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:45.641633Z","iopub.execute_input":"2024-06-03T07:01:45.641925Z","iopub.status.idle":"2024-06-03T07:01:45.652908Z","shell.execute_reply.started":"2024-06-03T07:01:45.641898Z","shell.execute_reply":"2024-06-03T07:01:45.652000Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def loss_function(logits, labels):\n    padding_mask = (labels != tokenizer.pad_token_id)\n \n    # One-hot encode the labels\n    one_hot_labels = jax.nn.one_hot(labels, num_classes=logits.shape[-1])\n    \n    # Compute the cross-entropy loss\n    cross_entropy_loss = optax.softmax_cross_entropy(logits, one_hot_labels)\n\n    # Apply the padding mask to the loss\n    loss = jnp.sum(cross_entropy_loss * padding_mask, axis=-1) / jnp.sum(padding_mask, axis=-1)\n    return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:45.655582Z","iopub.execute_input":"2024-06-03T07:01:45.655899Z","iopub.status.idle":"2024-06-03T07:01:45.663932Z","shell.execute_reply.started":"2024-06-03T07:01:45.655874Z","shell.execute_reply":"2024-06-03T07:01:45.662612Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"state = TrainState.create(\n    apply_fn=model.__call__,\n    params=model.params,\n    tx=optax.adamw(learning_rate=learning_rate_function),\n    loss_function=loss_function,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:45.665535Z","iopub.execute_input":"2024-06-03T07:01:45.665849Z","iopub.status.idle":"2024-06-03T07:01:46.022111Z","shell.execute_reply.started":"2024-06-03T07:01:45.665825Z","shell.execute_reply":"2024-06-03T07:01:46.021121Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@jit\ndef train_step(state, batch, dropout_rng):\n    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n    \n    def compute_loss(params):\n        logits = state.apply_fn(\n            input_ids=batch['input_ids'], \n            attention_mask=batch['attention_mask'], \n            params=params, \n            dropout_rng=dropout_rng, \n            train=True\n        ).logits\n        loss = state.loss_function(logits, batch['labels'])\n        return loss\n    \n    loss, grads = jax.value_and_grad(compute_loss)(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state, loss, new_dropout_rng","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:46.023356Z","iopub.execute_input":"2024-06-03T07:01:46.023648Z","iopub.status.idle":"2024-06-03T07:01:46.030880Z","shell.execute_reply.started":"2024-06-03T07:01:46.023624Z","shell.execute_reply":"2024-06-03T07:01:46.029814Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"@jit\ndef eval_step(state, batch):\n    outputs = state.apply_fn(\n        input_ids=batch['input_ids'], \n        attention_mask=batch['attention_mask'], \n        params=state.params, \n        train=False\n    )\n    logits = outputs[0]\n    loss = state.loss_function(logits, batch['labels'])\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:46.032087Z","iopub.execute_input":"2024-06-03T07:01:46.032404Z","iopub.status.idle":"2024-06-03T07:01:46.041991Z","shell.execute_reply.started":"2024-06-03T07:01:46.032379Z","shell.execute_reply":"2024-06-03T07:01:46.041184Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Training loop\nrng = jax.random.PRNGKey(0)\ndropout_rngs = rng","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:46.043179Z","iopub.execute_input":"2024-06-03T07:01:46.043519Z","iopub.status.idle":"2024-06-03T07:01:46.054375Z","shell.execute_reply.started":"2024-06-03T07:01:46.043495Z","shell.execute_reply":"2024-06-03T07:01:46.053552Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"total_batch_size = config['per_device_batch_size'] * jax.local_device_count()\nprint(\"The overall batch size (both for training and eval) is\", total_batch_size)\n\nstart_time = time()\nprint('======== Start training ======== ')\nfor epoch in range(config['epochs']):\n    training_loss = 0\n    with tqdm(total=len(train_loader), desc=\"Training...\", leave=False) as progress_bar_train:\n        for batch in train_loader: \n            state, loss, dropout_rngs = train_step(state, batch, dropout_rngs)\n            training_loss += jax.device_get(loss)\n            progress_bar_train.update(1)\n        training_loss = training_loss / len(train_loader)\n        \n    eval_loss = 0\n    with tqdm(total=len(val_loader), desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n        for batch in val_loader: \n            loss = eval_step(state, batch)\n            eval_loss += jax.device_get(loss)\n            progress_bar_eval.update(1)\n        eval_loss = eval_loss / len(val_loader)\n    \n    print(f\"Epoch {epoch + 1}: Training loss = {training_loss}, Val loss = {eval_loss}\")\n    \nprint('======== End training ========')\ntotal_training_time = time() - start_time\nprint(f\"Total training time: {total_training_time}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:01:46.055658Z","iopub.execute_input":"2024-06-03T07:01:46.055994Z","iopub.status.idle":"2024-06-03T08:34:52.290729Z","shell.execute_reply.started":"2024-06-03T07:01:46.055958Z","shell.execute_reply":"2024-06-03T08:34:52.289754Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The overall batch size (both for training and eval) is 64\n======== Start training ======== \n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Training loss = 5.285857452804076, Val loss = 5.023292985073356\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Training loss = 5.003126142740944, Val loss = 4.915793815878935\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Training loss = 4.908296616501433, Val loss = 4.854043594626493\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Training loss = 4.84413925593518, Val loss = 4.817263567724893\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Training loss = 4.802144354216907, Val loss = 4.794698072034259\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Training loss = 4.771681739707035, Val loss = 4.777872708786366\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Training loss = 4.749162184045197, Val loss = 4.766490097933037\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Training loss = 4.732483908316832, Val loss = 4.762231349945068\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Training loss = 4.720306410664372, Val loss = 4.754921088107797\n","output_type":"stream"},{"name":"stderr","text":"                                                                ","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Training loss = 4.713775796306376, Val loss = 4.754215644126715\n======== End training ========\nTotal training time: 5586.224370002747\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}