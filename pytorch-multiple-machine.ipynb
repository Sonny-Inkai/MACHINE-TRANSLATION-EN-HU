{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Sonny"]},{"cell_type":"markdown","metadata":{},"source":["t5-small 128\n","MarianMTModel - 64"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-02T01:56:06.389179Z"},"trusted":true},"outputs":[],"source":["import os\n","from accelerate.utils import write_basic_config\n","write_basic_config() # Write a config file\n","os._exit(00) # Restart the notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:44:26.630577Z","iopub.status.busy":"2024-06-02T01:44:26.629890Z","iopub.status.idle":"2024-06-02T01:44:39.940335Z","shell.execute_reply":"2024-06-02T01:44:39.939412Z","shell.execute_reply.started":"2024-06-02T01:44:26.630541Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install sacremoses -q"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:54:24.174447Z","iopub.status.busy":"2024-06-02T03:54:24.174069Z","iopub.status.idle":"2024-06-02T03:54:36.901293Z","shell.execute_reply":"2024-06-02T03:54:36.900155Z","shell.execute_reply.started":"2024-06-02T03:54:24.174416Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install sacrebleu -q"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import load_dataset, DatasetDict, load_metric\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, get_scheduler\n","from transformers import MarianMTModel, MarianTokenizer\n","\n","from torch.utils.data import DataLoader\n","from accelerate import Accelerator, notebook_launcher\n","from accelerate.utils import set_seed\n","from torch.optim import AdamW\n","from time import time\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:16.592839Z","iopub.status.busy":"2024-06-02T01:56:16.592328Z","iopub.status.idle":"2024-06-02T01:56:18.157705Z","shell.execute_reply":"2024-06-02T01:56:18.156764Z","shell.execute_reply.started":"2024-06-02T01:56:16.592810Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset('Helsinki-NLP/opus_books', 'en-hu')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:18.159334Z","iopub.status.busy":"2024-06-02T01:56:18.158974Z","iopub.status.idle":"2024-06-02T01:56:18.167299Z","shell.execute_reply":"2024-06-02T01:56:18.166264Z","shell.execute_reply.started":"2024-06-02T01:56:18.159300Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': '0',\n"," 'translation': {'en': 'Source: Project GutenbergAudiobook available here',\n","  'hu': 'Source: mek.oszk.huTranslation: Szenczi Mikl√≥sAudiobook available here'}}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'][0]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:18.169572Z","iopub.status.busy":"2024-06-02T01:56:18.169333Z","iopub.status.idle":"2024-06-02T01:56:18.184545Z","shell.execute_reply":"2024-06-02T01:56:18.183783Z","shell.execute_reply.started":"2024-06-02T01:56:18.169551Z"},"trusted":true},"outputs":[],"source":["val_test_set = dataset['train'].train_test_split(test_size=0.2, seed=42)\n","test_set = val_test_set['test'].train_test_split(test_size=0.5, seed=42)\n","\n","dataset = DatasetDict({\n","    'train': val_test_set['train'],\n","    'val': test_set['test'],\n","    'test': test_set['train']\n","})"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:18.186353Z","iopub.status.busy":"2024-06-02T01:56:18.185766Z","iopub.status.idle":"2024-06-02T01:56:18.192988Z","shell.execute_reply":"2024-06-02T01:56:18.192071Z","shell.execute_reply.started":"2024-06-02T01:56:18.186321Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'translation'],\n","        num_rows: 109720\n","    })\n","    val: Dataset({\n","        features: ['id', 'translation'],\n","        num_rows: 13716\n","    })\n","    test: Dataset({\n","        features: ['id', 'translation'],\n","        num_rows: 13715\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:18.194397Z","iopub.status.busy":"2024-06-02T01:56:18.194076Z","iopub.status.idle":"2024-06-02T01:56:18.200531Z","shell.execute_reply":"2024-06-02T01:56:18.199667Z","shell.execute_reply.started":"2024-06-02T01:56:18.194372Z"},"trusted":true},"outputs":[],"source":["def get_config():\n","    config = {\n","        'model_name': 'Helsinki-NLP/opus-mt-en-hu', # 't5-small', \n","        'max_length': 128,\n","        'batch_size': 64,\n","        'lr': 10 ** -5,\n","        'epochs': 10,\n","        'seed': 42,\n","        'metric_name': 'sacrebleu',\n","        'save_model': '/kaggle/working/model.pth',\n","        \n","    }\n","    return config"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:29.127108Z","iopub.status.busy":"2024-06-02T01:56:29.126746Z","iopub.status.idle":"2024-06-02T01:56:29.131387Z","shell.execute_reply":"2024-06-02T01:56:29.130448Z","shell.execute_reply.started":"2024-06-02T01:56:29.127079Z"},"trusted":true},"outputs":[],"source":["config = get_config()"]},{"cell_type":"markdown","metadata":{},"source":["### DataLoader"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:30.937246Z","iopub.status.busy":"2024-06-02T01:56:30.936232Z","iopub.status.idle":"2024-06-02T01:56:30.942391Z","shell.execute_reply":"2024-06-02T01:56:30.941510Z","shell.execute_reply.started":"2024-06-02T01:56:30.937198Z"},"trusted":true},"outputs":[],"source":["def get_dataloader(dataset, config, is_train):\n","    if is_train == True:\n","        return DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n","    else:\n","        return DataLoader(dataset, batch_size=config['batch_size'], drop_last=False, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:36:29.927757Z","iopub.status.busy":"2024-06-02T01:36:29.927472Z","iopub.status.idle":"2024-06-02T01:36:29.934344Z","shell.execute_reply":"2024-06-02T01:36:29.933446Z","shell.execute_reply.started":"2024-06-02T01:36:29.927734Z"},"trusted":true},"outputs":[],"source":["train_loader = get_dataloader(dataset['train'], config, True)\n","val_loader = get_dataloader(dataset['val'], config, False)\n","test_loader = get_dataloader(dataset['test'], config, False)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T01:56:33.506010Z","iopub.status.busy":"2024-06-02T01:56:33.505123Z","iopub.status.idle":"2024-06-02T01:56:35.560382Z","shell.execute_reply":"2024-06-02T01:56:35.559530Z","shell.execute_reply.started":"2024-06-02T01:56:33.505974Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msonnyinkai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","# Replace 'your-api-key' with your actual wandb API key\n","wandb.login(key='06cc95a1f4faf48400aa0bf5e162b3ace6237a45')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T02:03:16.486776Z","iopub.status.busy":"2024-06-02T02:03:16.486403Z","iopub.status.idle":"2024-06-02T02:03:16.510285Z","shell.execute_reply":"2024-06-02T02:03:16.509110Z","shell.execute_reply.started":"2024-06-02T02:03:16.486746Z"},"trusted":true},"outputs":[],"source":["def train():\n","    set_seed(config['seed'])\n","    accelerator = Accelerator(mixed_precision='fp16', log_with='wandb')\n","\n","    # Initialize tokenizer and model\n","    tokenizer = MarianTokenizer.from_pretrained(config['model_name'])\n","    model = MarianMTModel.from_pretrained(config['model_name'])\n","\n","    # Initialize dataloaders\n","    train_loader = get_dataloader(dataset['train'], config, True)\n","    val_loader = get_dataloader(dataset['val'], config, False)\n","\n","    # Initialize optimizer\n","    optimizer = AdamW(model.parameters(), lr=config['lr'])\n","\n","    # Initialize lr scheduler\n","    num_training_steps = len(train_loader) * config['epochs']\n","    lr_scheduler = get_scheduler('cosine', optimizer=optimizer, num_training_steps=num_training_steps, num_warmup_steps=0)\n","\n","    # Prepare with accelerator\n","    model, optimizer, train_loader, val_loader, lr_scheduler = accelerator.prepare(model, optimizer, train_loader, val_loader, lr_scheduler)\n","\n","    accelerator.init_trackers('Machine Translation')\n","\n","    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    accelerator.print(f'Number of training parameters: {n_parameters}')\n","    accelerator.print(f\"Batch size: {config['batch_size']}\")\n","    start_time = time()\n","    accelerator.print('======== Start training ======== ')\n","    \n","    # Training loop\n","    for epoch in range(config['epochs']):\n","        model.train()\n","        training_loss = 0\n","        for data in train_loader:\n","            optimizer.zero_grad()\n","            src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(accelerator.device)\n","            labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt')\n","\n","            outputs = model(**src, labels=labels.input_ids.to(accelerator.device))\n","            logits = outputs.logits\n","            loss = torch.nn.CrossEntropyLoss(logits,labels)\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            \n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","\n","            training_loss += loss.item()\n","            \n","            accelerator.log({\"Training loss\": training_loss})\n","\n","        training_loss = training_loss / len(train_loader)\n","        accelerator.log({\"Training loss\": training_loss})\n","\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for data in val_loader:\n","                src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(accelerator.device)\n","                labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt')\n","\n","                outputs = model(**src, labels=labels.input_ids.to(accelerator.device))\n","                loss = outputs.loss\n","\n","                val_loss += loss.item()\n","\n","        val_loss = val_loss / len(val_loader)\n","        accelerator.log({\"Val loss\": val_loss})\n","        accelerator.print(f\"Epoch {epoch + 1}: Training loss = {training_loss}, Val loss = {val_loss}\")\n","\n","    accelerator.print('======== End training ========')\n","    total_training_time = time() - start_time\n","    accelerator.print(f\"Total training time: {total_training_time}\")\n","\n","    # Save model\n","    accelerator.wait_for_everyone()\n","    model = accelerator.unwrap_model(model)\n","    accelerator.save(model, config['save_model'])\n","    accelerator.end_training()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T02:03:14.589293Z","iopub.status.busy":"2024-06-02T02:03:14.588345Z","iopub.status.idle":"2024-06-02T02:03:14.596274Z","shell.execute_reply":"2024-06-02T02:03:14.595367Z","shell.execute_reply.started":"2024-06-02T02:03:14.589245Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T02:04:12.919578Z","iopub.status.busy":"2024-06-02T02:04:12.919215Z","iopub.status.idle":"2024-06-02T03:28:33.537115Z","shell.execute_reply":"2024-06-02T03:28:33.535858Z","shell.execute_reply.started":"2024-06-02T02:04:12.919552Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Launching training on 2 GPUs.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240602_020418-knpavko5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/knpavko5' target=\"_blank\">quiet-sky-17</a></strong> to <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/knpavko5' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation/runs/knpavko5</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of training parameters: 76149760\n","Batch size: 64\n","======== Start training ======== \n","Epoch 1: Training loss = 1.7197015921135883, Val loss = 1.2082806748372537\n","Epoch 2: Training loss = 1.1870478390952646, Val loss = 1.0266323757392388\n","Epoch 3: Training loss = 1.0526310902236502, Val loss = 0.9404577066500982\n","Epoch 4: Training loss = 0.9819862646656436, Val loss = 0.890795718188639\n","Epoch 5: Training loss = 0.9354820445284143, Val loss = 0.8604172170162201\n","Epoch 6: Training loss = 0.9096408127904771, Val loss = 0.8410754987487087\n","Epoch 7: Training loss = 0.8874246104336008, Val loss = 0.8301579163030341\n","Epoch 8: Training loss = 0.8770192352347163, Val loss = 0.8242287288109461\n","Epoch 9: Training loss = 0.8730430450889614, Val loss = 0.8222033762269549\n","Epoch 10: Training loss = 0.8676336767512324, Val loss = 0.8218545957847878\n","======== End training ========\n","Total training time: 5034.0282661914825\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.07578827073918239, max=1.‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Val loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.86763</td></tr><tr><td>Val loss</td><td>0.82185</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">quiet-sky-17</strong> at: <a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/knpavko5' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation/runs/knpavko5</a><br/> View project at: <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240602_020418-knpavko5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_launcher(train, num_processes=2)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:48:50.277699Z","iopub.status.busy":"2024-06-02T03:48:50.277332Z","iopub.status.idle":"2024-06-02T03:48:50.282484Z","shell.execute_reply":"2024-06-02T03:48:50.281437Z","shell.execute_reply.started":"2024-06-02T03:48:50.277669Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:48:24.653249Z","iopub.status.busy":"2024-06-02T03:48:24.652904Z","iopub.status.idle":"2024-06-02T03:48:24.880221Z","shell.execute_reply":"2024-06-02T03:48:24.879453Z","shell.execute_reply.started":"2024-06-02T03:48:24.653203Z"},"trusted":true},"outputs":[],"source":["model = torch.load('/kaggle/working/model.pth', map_location='cpu')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:54:46.440885Z","iopub.status.busy":"2024-06-02T03:54:46.440508Z","iopub.status.idle":"2024-06-02T03:54:46.856997Z","shell.execute_reply":"2024-06-02T03:54:46.856275Z","shell.execute_reply.started":"2024-06-02T03:54:46.440853Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/sacrebleu/sacrebleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]}],"source":["metric = load_metric(\"sacrebleu\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:54:59.324782Z","iopub.status.busy":"2024-06-02T03:54:59.323321Z","iopub.status.idle":"2024-06-02T03:54:59.329403Z","shell.execute_reply":"2024-06-02T03:54:59.328450Z","shell.execute_reply.started":"2024-06-02T03:54:59.324739Z"},"trusted":true},"outputs":[],"source":["test_loader = get_dataloader(dataset['test'], config, False)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T03:55:01.442665Z","iopub.status.busy":"2024-06-02T03:55:01.441998Z","iopub.status.idle":"2024-06-02T03:55:02.151003Z","shell.execute_reply":"2024-06-02T03:55:02.150109Z","shell.execute_reply.started":"2024-06-02T03:55:01.442630Z"},"trusted":true},"outputs":[],"source":["tokenizer = MarianTokenizer.from_pretrained(config['model_name'])"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T04:18:28.205775Z","iopub.status.busy":"2024-06-02T04:18:28.205366Z","iopub.status.idle":"2024-06-02T04:18:28.215590Z","shell.execute_reply":"2024-06-02T04:18:28.214598Z","shell.execute_reply.started":"2024-06-02T04:18:28.205748Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, tokenizer, test_loader, metric, device):\n","    test_loss = 0 \n","    bleu_score = 0 \n","\n","    model.to(device)\n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for data in test_loader:\n","            # Tokenize the input and labels\n","            src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(device)\n","            labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(device)\n","            \n","            # Forward pass\n","            outputs = model(**src, labels=labels.input_ids)\n","            loss = outputs.loss\n","\n","            test_loss += loss.item()\n","\n","            # Generate predictions\n","            predictions = model.generate(input_ids=src.input_ids, attention_mask=src.attention_mask)\n","            decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","            decoded_labels = tokenizer.batch_decode(labels.input_ids, skip_special_tokens=True)\n","\n","            # Calculate BLEU score\n","            decoded_labels = [[label] for label in decoded_labels]\n","            result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","            bleu_score += result['score']\n","\n","    # Calculate average loss and BLEU score\n","    test_loss = test_loss / len(test_loader)\n","    bleu_score = bleu_score / len(test_loader)\n","    print(f\"Test loss is: {test_loss} and BLEU score is: {bleu_score}\")\n","\n","    return test_loss, bleu_score\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T04:18:28.429254Z","iopub.status.busy":"2024-06-02T04:18:28.428941Z","iopub.status.idle":"2024-06-02T04:48:06.964841Z","shell.execute_reply":"2024-06-02T04:48:06.963732Z","shell.execute_reply.started":"2024-06-02T04:18:28.429215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss is: 0.8217921686726947 and BLEU score is: 9.359375810821396\n"]},{"data":{"text/plain":["(0.8217921686726947, 9.359375810821396)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(model, tokenizer, test_loader, metric, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
