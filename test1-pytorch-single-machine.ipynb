{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Sonny","metadata":{}},{"cell_type":"markdown","source":"t5-small 128\nMarianMTModel - 64","metadata":{}},{"cell_type":"code","source":"import os\nfrom accelerate.utils import write_basic_config\nwrite_basic_config() # Write a config file\nos._exit(00) # Restart the notebook","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:42:12.440248Z","iopub.execute_input":"2024-06-03T04:42:12.440655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sacremoses -q","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:43:34.899713Z","iopub.execute_input":"2024-06-03T04:43:34.900465Z","iopub.status.idle":"2024-06-03T04:43:48.137193Z","shell.execute_reply.started":"2024-06-03T04:43:34.900431Z","shell.execute_reply":"2024-06-03T04:43:48.135973Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sacrebleu -q","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:43:48.139147Z","iopub.execute_input":"2024-06-03T04:43:48.139483Z","iopub.status.idle":"2024-06-03T04:44:00.817070Z","shell.execute_reply.started":"2024-06-03T04:43:48.139456Z","shell.execute_reply":"2024-06-03T04:44:00.816165Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, load_metric\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, get_scheduler\nfrom transformers import MarianMTModel, MarianTokenizer\n\nfrom torch.utils.data import DataLoader\nfrom accelerate import Accelerator, notebook_launcher\nfrom accelerate.utils import set_seed\nfrom torch.optim import AdamW\nfrom time import time\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:00.818528Z","iopub.execute_input":"2024-06-03T04:44:00.818907Z","iopub.status.idle":"2024-06-03T04:44:16.348456Z","shell.execute_reply.started":"2024-06-03T04:44:00.818870Z","shell.execute_reply":"2024-06-03T04:44:16.347530Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-03 04:44:06.641236: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-03 04:44:06.641356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-03 04:44:06.774549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset('Helsinki-NLP/opus_books', 'en-hu')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:16.351259Z","iopub.execute_input":"2024-06-03T04:44:16.352183Z","iopub.status.idle":"2024-06-03T04:44:18.853322Z","shell.execute_reply.started":"2024-06-03T04:44:16.352154Z","shell.execute_reply":"2024-06-03T04:44:18.852616Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/28.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d4de1e43bb4957887a25c6046eae3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/23.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24977e5f714c48a1badcf0b787c8c4e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/137151 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"348500cad0a54a338c07d3ad2f51cff3"}},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:18.854324Z","iopub.execute_input":"2024-06-03T04:44:18.854603Z","iopub.status.idle":"2024-06-03T04:44:18.864049Z","shell.execute_reply.started":"2024-06-03T04:44:18.854559Z","shell.execute_reply":"2024-06-03T04:44:18.863214Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'translation': {'en': 'Source: Project GutenbergAudiobook available here',\n  'hu': 'Source: mek.oszk.huTranslation: Szenczi Mikl√≥sAudiobook available here'}}"},"metadata":{}}]},{"cell_type":"code","source":"val_test_set = dataset['train'].train_test_split(test_size=0.2, seed=42)\ntest_set = val_test_set['test'].train_test_split(test_size=0.5, seed=42)\n\ndataset = DatasetDict({\n    'train': val_test_set['train'],\n    'val': test_set['test'],\n    'test': test_set['train']\n})","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:18.865154Z","iopub.execute_input":"2024-06-03T04:44:18.865425Z","iopub.status.idle":"2024-06-03T04:44:19.056038Z","shell.execute_reply.started":"2024-06-03T04:44:18.865402Z","shell.execute_reply":"2024-06-03T04:44:19.055279Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.057071Z","iopub.execute_input":"2024-06-03T04:44:19.057332Z","iopub.status.idle":"2024-06-03T04:44:19.062869Z","shell.execute_reply.started":"2024-06-03T04:44:19.057309Z","shell.execute_reply":"2024-06-03T04:44:19.061965Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 109720\n    })\n    val: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 13716\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 13715\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def get_config():\n    config = {\n        'model_name': 'Helsinki-NLP/opus-mt-en-hu', # 't5-small', \n        'max_length': 128,\n        'batch_size': 64,\n        'lr': 10 ** -5,\n        'epochs': 10,\n        'seed': 42,\n        'metric_name': 'sacrebleu',\n        'save_model': '/kaggle/working/model.pth',\n        \n    }\n    return config","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.063945Z","iopub.execute_input":"2024-06-03T04:44:19.064186Z","iopub.status.idle":"2024-06-03T04:44:19.074019Z","shell.execute_reply.started":"2024-06-03T04:44:19.064165Z","shell.execute_reply":"2024-06-03T04:44:19.073082Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"config = get_config()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.075136Z","iopub.execute_input":"2024-06-03T04:44:19.075402Z","iopub.status.idle":"2024-06-03T04:44:19.082020Z","shell.execute_reply.started":"2024-06-03T04:44:19.075379Z","shell.execute_reply":"2024-06-03T04:44:19.081288Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"def get_dataloader(dataset, config, is_train):\n    if is_train == True:\n        return DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n    else:\n        return DataLoader(dataset, batch_size=config['batch_size'], drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.085089Z","iopub.execute_input":"2024-06-03T04:44:19.085363Z","iopub.status.idle":"2024-06-03T04:44:19.091039Z","shell.execute_reply.started":"2024-06-03T04:44:19.085333Z","shell.execute_reply":"2024-06-03T04:44:19.090065Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader = get_dataloader(dataset['train'], config, True)\nval_loader = get_dataloader(dataset['val'], config, False)\ntest_loader = get_dataloader(dataset['test'], config, False)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.091938Z","iopub.execute_input":"2024-06-03T04:44:19.092179Z","iopub.status.idle":"2024-06-03T04:44:19.099741Z","shell.execute_reply.started":"2024-06-03T04:44:19.092158Z","shell.execute_reply":"2024-06-03T04:44:19.098799Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"import wandb\n\n# Replace 'your-api-key' with your actual wandb API key\nwandb.login(key='06cc95a1f4faf48400aa0bf5e162b3ace6237a45')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:19.100745Z","iopub.execute_input":"2024-06-03T04:44:19.101016Z","iopub.status.idle":"2024-06-03T04:44:21.610095Z","shell.execute_reply.started":"2024-06-03T04:44:19.100994Z","shell.execute_reply":"2024-06-03T04:44:21.609136Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def train():\n    set_seed(config['seed'])\n    accelerator = Accelerator(mixed_precision='fp16', log_with='wandb')\n\n    # Initialize tokenizer and model\n    tokenizer = MarianTokenizer.from_pretrained(config['model_name'])\n    model = MarianMTModel.from_pretrained(config['model_name'])\n\n    # Initialize dataloaders\n    train_loader = get_dataloader(dataset['train'], config, True)\n    val_loader = get_dataloader(dataset['val'], config, False)\n\n    # Initialize optimizer\n    optimizer = AdamW(model.parameters(), lr=config['lr'])\n\n    # Initialize lr scheduler\n    num_training_steps = len(train_loader) * config['epochs']\n    lr_scheduler = get_scheduler('cosine', optimizer=optimizer, num_training_steps=num_training_steps, num_warmup_steps=0)\n\n    # Prepare with accelerator\n    model, optimizer, train_loader, val_loader, lr_scheduler = accelerator.prepare(model, optimizer, train_loader, val_loader, lr_scheduler)\n\n    accelerator.init_trackers('Machine Translation')\n\n    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    accelerator.print(f'Number of training parameters: {n_parameters}')\n    accelerator.print(f\"Batch size: {config['batch_size']}\")\n    start_time = time()\n    accelerator.print('======== Start training ======== ')\n    \n    # Training loop\n    for epoch in range(config['epochs']):\n        model.train()\n        training_loss = 0\n        for data in train_loader:\n            optimizer.zero_grad()\n            src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(accelerator.device)\n            labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt')\n\n            outputs = model(**src, labels=labels.input_ids.to(accelerator.device))\n            loss = outputs.loss\n\n            accelerator.backward(loss)\n            optimizer.step()\n            \n            lr_scheduler.step()\n            optimizer.zero_grad()\n\n            training_loss += loss.item()\n            \n\n        training_loss = training_loss / len(train_loader)\n        accelerator.log({\"Training loss\": training_loss})\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for data in val_loader:\n                src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(accelerator.device)\n                labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt')\n\n                outputs = model(**src, labels=labels.input_ids.to(accelerator.device))\n                loss = outputs.loss\n\n                val_loss += loss.item()\n\n        val_loss = val_loss / len(val_loader)\n        accelerator.log({\"Val loss\": val_loss})\n        accelerator.print(f\"Epoch {epoch + 1}: Training loss = {training_loss}, Val loss = {val_loss}\")\n\n    accelerator.print('======== End training ========')\n    total_training_time = time() - start_time\n    accelerator.print(f\"Total training time: {total_training_time}\")\n\n    # Save model\n    accelerator.wait_for_everyone()\n    model = accelerator.unwrap_model(model)\n    accelerator.save(model, config['save_model'])\n    accelerator.end_training()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:21.611331Z","iopub.execute_input":"2024-06-03T04:44:21.611926Z","iopub.status.idle":"2024-06-03T04:44:21.630618Z","shell.execute_reply.started":"2024-06-03T04:44:21.611901Z","shell.execute_reply":"2024-06-03T04:44:21.629735Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:21.631883Z","iopub.execute_input":"2024-06-03T04:44:21.632309Z","iopub.status.idle":"2024-06-03T04:44:21.643796Z","shell.execute_reply.started":"2024-06-03T04:44:21.632278Z","shell.execute_reply":"2024-06-03T04:44:21.642994Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"notebook_launcher(train, num_processes=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T04:44:21.644926Z","iopub.execute_input":"2024-06-03T04:44:21.645155Z","iopub.status.idle":"2024-06-03T07:12:04.939325Z","shell.execute_reply.started":"2024-06-03T04:44:21.645135Z","shell.execute_reply":"2024-06-03T07:12:04.938192Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Launching training on one GPU.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80c7717d07d045d0b158fd16c53276ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb08e369c984f89adcb0027eb096987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/850k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"196feecc3644424d8c45e7d2943a469e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.57M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc82528f11c4e66bcb899ec0c3d10b0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d3477beb724f56babaf99c3d4f8587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d11b16b31b1840a6922b3f016b3c65b0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2e661f804b468e9f2b49f5a35d0c3f"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msonnyinkai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240603_044433-0hg7jbac</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/0hg7jbac' target=\"_blank\">revived-waterfall-18</a></strong> to <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/0hg7jbac' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation/runs/0hg7jbac</a>"},"metadata":{}},{"name":"stdout","text":"Number of training parameters: 76149760\nBatch size: 64\n======== Start training ======== \nEpoch 1: Training loss = 1.5007214059287535, Val loss = 1.0807931608931962\nEpoch 2: Training loss = 1.0589040026720342, Val loss = 0.9280746623527172\nEpoch 3: Training loss = 0.9452528844769426, Val loss = 0.8577722413595332\nEpoch 4: Training loss = 0.8840221967015948, Val loss = 0.8187148321506589\nEpoch 5: Training loss = 0.8456609952554063, Val loss = 0.794529776240504\nEpoch 6: Training loss = 0.8214690263695341, Val loss = 0.7794745822285497\nEpoch 7: Training loss = 0.8062448008414955, Val loss = 0.7708109947138054\nEpoch 8: Training loss = 0.7972726668977876, Val loss = 0.7664283968681513\nEpoch 9: Training loss = 0.792685797541204, Val loss = 0.7649582776912424\nEpoch 10: Training loss = 0.7915419358206213, Val loss = 0.7646468841752341\n======== End training ========\nTotal training time: 8829.482492923737\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÖ</td></tr><tr><td>Val loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.79154</td></tr><tr><td>Val loss</td><td>0.76465</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">revived-waterfall-18</strong> at: <a href='https://wandb.ai/sonnyinkai/Machine%20Translation/runs/0hg7jbac' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation/runs/0hg7jbac</a><br/> View project at: <a href='https://wandb.ai/sonnyinkai/Machine%20Translation' target=\"_blank\">https://wandb.ai/sonnyinkai/Machine%20Translation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240603_044433-0hg7jbac/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:38:00.735734Z","iopub.execute_input":"2024-06-03T07:38:00.736062Z","iopub.status.idle":"2024-06-03T07:38:00.743773Z","shell.execute_reply.started":"2024-06-03T07:38:00.736032Z","shell.execute_reply":"2024-06-03T07:38:00.742843Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/model.pth', map_location='cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:04.946715Z","iopub.execute_input":"2024-06-03T07:12:04.947397Z","iopub.status.idle":"2024-06-03T07:12:05.139729Z","shell.execute_reply.started":"2024-06-03T07:12:04.947373Z","shell.execute_reply":"2024-06-03T07:12:05.138741Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"metric = load_metric(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:05.141115Z","iopub.execute_input":"2024-06-03T07:12:05.141795Z","iopub.status.idle":"2024-06-03T07:12:05.557552Z","shell.execute_reply.started":"2024-06-03T07:12:05.141767Z","shell.execute_reply":"2024-06-03T07:12:05.556808Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_104/2163898601.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"sacrebleu\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/sacrebleu/sacrebleu.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"175b6922fa854bfeafa172abe5c7b45b"}},"metadata":{}}]},{"cell_type":"code","source":"test_loader = get_dataloader(dataset['test'], config, False)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:05.558653Z","iopub.execute_input":"2024-06-03T07:12:05.559409Z","iopub.status.idle":"2024-06-03T07:12:05.563825Z","shell.execute_reply.started":"2024-06-03T07:12:05.559381Z","shell.execute_reply":"2024-06-03T07:12:05.562887Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = MarianTokenizer.from_pretrained(config['model_name'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:05.565050Z","iopub.execute_input":"2024-06-03T07:12:05.565386Z","iopub.status.idle":"2024-06-03T07:12:05.845447Z","shell.execute_reply.started":"2024-06-03T07:12:05.565356Z","shell.execute_reply":"2024-06-03T07:12:05.844640Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, tokenizer, test_loader, metric, device):\n    test_loss = 0 \n    bleu_score = 0 \n\n    model.to(device)\n    model.eval()\n    \n    with torch.no_grad():\n        for data in test_loader:\n            # Tokenize the input and labels\n            src = tokenizer(data['translation']['en'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(device)\n            labels = tokenizer(data['translation']['hu'], max_length=config['max_length'], truncation=True, padding='longest', return_tensors='pt').to(device)\n            \n            # Forward pass\n            outputs = model(**src, labels=labels.input_ids)\n            loss = outputs.loss\n\n            test_loss += loss.item()\n\n            # Generate predictions\n            predictions = model.generate(input_ids=src.input_ids, attention_mask=src.attention_mask)\n            decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n            decoded_labels = tokenizer.batch_decode(labels.input_ids, skip_special_tokens=True)\n\n            # Calculate BLEU score\n            decoded_labels = [[label] for label in decoded_labels]\n            result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n            bleu_score += result['score']\n\n    # Calculate average loss and BLEU score\n    test_loss = test_loss / len(test_loader)\n    bleu_score = bleu_score / len(test_loader)\n    print(f\"Test loss is: {test_loss} and BLEU score is: {bleu_score}\")\n\n    return test_loss, bleu_score\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:05.846491Z","iopub.execute_input":"2024-06-03T07:12:05.846769Z","iopub.status.idle":"2024-06-03T07:12:05.856687Z","shell.execute_reply.started":"2024-06-03T07:12:05.846747Z","shell.execute_reply":"2024-06-03T07:12:05.855773Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"evaluate(model, tokenizer, test_loader, metric, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:12:05.857913Z","iopub.execute_input":"2024-06-03T07:12:05.858245Z","iopub.status.idle":"2024-06-03T07:38:00.701309Z","shell.execute_reply.started":"2024-06-03T07:12:05.858215Z","shell.execute_reply":"2024-06-03T07:38:00.700403Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Test loss is: 0.7575763915860376 and BLEU score is: 10.135359818478044\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(0.7575763915860376, 10.135359818478044)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}